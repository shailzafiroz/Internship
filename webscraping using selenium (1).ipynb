{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.naukri.com/\"\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "ser_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "ser_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the job titles can be extracted\n",
    "\n",
    "job_title=[]\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name=[]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the job location can be extracted\n",
    "\n",
    "job_loc=[]\n",
    "for i in loc_tags:\n",
    "    job_loc.append(i.text)\n",
    "job_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the experience\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the job location can be extracted\n",
    "\n",
    "experience=[]\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "naukrijob=pd.DataFrame(())\n",
    "naukrijob['Job Title']=job_title[0:10]\n",
    "naukrijob['Job Location']=job_loc[0:10]\n",
    "naukrijob['Company Name']=company_name[0:10]\n",
    "naukrijob['Experience']=experience[0:10]\n",
    "\n",
    "naukrijob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.naukri.com/\"\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "serch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "ser_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags\n",
    "# becoz text do not work in text so we use loop so that the job titles can be extracted\n",
    "\n",
    "job_title=[]\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name=[]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "loc_tags\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the job location can be extracted\n",
    "\n",
    "job_loc=[]\n",
    "for i in loc_tags:\n",
    "    job_loc.append(i.text)\n",
    "job_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpurl=[]\n",
    "\n",
    "for i in url:\n",
    "    jpurl.append(i.get_attribute('href'))\n",
    "jpurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_position=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in jpurl:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting Job Position\n",
    "    try:\n",
    "        job_position=driver.find_element_by_xpath(\"//div[@class='nConfig_textblock ']//div\")\n",
    "        job_position.append(job_position.text)\n",
    "    except:\n",
    "       job_position.append('--')\n",
    "        \n",
    "job_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "naukrijob1=pd.DataFrame(())\n",
    "naukrijob1['Job Title']=job_title[0:10]\n",
    "naukrijob1['Job Location']=job_loc[0:10]\n",
    "naukrijob1['Company Name']=company_name[0:10]\n",
    "naukrijob1['Job Position']=job_position[0:10]\n",
    "\n",
    "naukrijob1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.naukri.com/\"\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "serch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_element_by_xpath(\"//label[@class='chkLbl']\")\n",
    "loc_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locfilter=driver.find_element_by_id(\"chk-Delhi / NCR-cityTypeGid-]\")\n",
    "locfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2=\"https://www.glassdoor.co.in/sitedirectory/title-jobs.htm\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job1=driver.find_element_by_id(\"scKeyword\")\n",
    "serch_job1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job1.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc1=driver.find_element_by_id(\"scLocation\")\n",
    "ser_loc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc1.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='pl-0 pr-xsm SearchStyles__searchKeywordSubmit']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags1=driver.find_elements_by_xpath(\"//a[@class=' job-search-key-l2wjgv e1n63ojh0 jobLink']\")\n",
    "company_tags1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name1=[]\n",
    "for i in company_tags1:\n",
    "    company_name1.append(i.text)\n",
    "company_name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the No of days job posted\n",
    "noofD=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "noofD\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the No of days job poste can be extracted\n",
    "\n",
    "Agejob=[]\n",
    "for i in noofD:\n",
    "    Agejob.append(i.text)\n",
    "Agejob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(\" \" in Agejob) :\n",
    "    Agejob.remove(\" \")\n",
    "Agejob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the rating\n",
    "rate=driver.find_elements_by_xpath(\"//li[@class='react-job-listing job-search-key-nhtksm eigr9kq0']//span[@class=' job-search-key-srfzj0 e1cjmv6j0']\")\n",
    "rate\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the rating can be extracted\n",
    "\n",
    "rating=[]\n",
    "for i in rate:\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "job=pd.DataFrame(())\n",
    "\n",
    "job['Company Name']=company_name1[0:10]\n",
    "job['No of days Job Posted']=Agejob[0:10]\n",
    "job['Rating']=rating[0:10]\n",
    "job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job2=driver.find_element_by_id(\"KeywordSearch\")\n",
    "serch_job2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job2.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc2=driver.find_element_by_id(\"LocationSearch\")\n",
    "ser_loc2.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags2=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "company_tags2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name2=[]\n",
    "for i in company_tags2:\n",
    "    company_name2.append(i.text)\n",
    "company_name2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the min_max salary\n",
    "min_max=driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "min_max\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the min_max salary can be extracted\n",
    "\n",
    "minimum_max=[]\n",
    "for i in min_max:\n",
    "    minimum_max.append(i.text)\n",
    "minimum_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the Average salary\n",
    "avg=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "avg\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Average salary can be extracted\n",
    "\n",
    "avg_sal=[]\n",
    "for i in avg:\n",
    "    avg_sal.append(i.text.replace(\"\\n\",\"\"))\n",
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the rating\n",
    "rate1=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-center mt-xxsm']\")\n",
    "rate1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the rating can be extracted\n",
    "\n",
    "rating1=[]\n",
    "for i in rate1:\n",
    "    rating1.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "job1=pd.DataFrame(())\n",
    "\n",
    "job1['Company Name']=company_name2[0:10]\n",
    "job1['Minimum Salary and Maxmimum Salary']=minimum_max[0:10]\n",
    "job1['Average Salary']=avg_sal[0:10]\n",
    "job1['Rating']=rating1[0:10]\n",
    "job1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4=\"https://www.flipkart.com/\"\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn1=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "ser_btn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand name\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "br\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "brand=[]\n",
    "for i in br:\n",
    "    brand.append(i.text)\n",
    "brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the description name\n",
    "desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "desc\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the description name can be extracted\n",
    "\n",
    "description=[]\n",
    "for i in desc:\n",
    "    description.append(i.text)\n",
    "description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the price\n",
    "pr=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "pr\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the price can be extracted\n",
    "\n",
    "price=[]\n",
    "for i in pr:\n",
    "    price.append(i.text)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the discount\n",
    "dis=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "dis\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the price can be extracted\n",
    "\n",
    "discount=[]\n",
    "for i in dis:\n",
    "    discount.append(i.text)\n",
    "discount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand name 41 -80\n",
    "br1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "br1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "brand1=[]\n",
    "for i in br1:\n",
    "    brand1.append(i.text)\n",
    "brand1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the description name 41-80\n",
    "desc1=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "desc1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the description name can be extracted\n",
    "\n",
    "description1=[]\n",
    "for i in desc1:\n",
    "    description1.append(i.text)\n",
    "description1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the price 41-80\n",
    "pr1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "pr1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the price can be extracted\n",
    "\n",
    "price1=[]\n",
    "for i in pr1:\n",
    "    price1.append(i.text)\n",
    "price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the discount 41-80\n",
    "dis1=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "dis1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the price can be extracted\n",
    "\n",
    "discount1=[]\n",
    "for i in dis1:\n",
    "    discount1.append(i.text)\n",
    "discount1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand name 81 -120\n",
    "br2=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "br2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "brand2=[]\n",
    "for i in br2:\n",
    "    brand2.append(i.text)\n",
    "brand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the description name 81-120\n",
    "desc2=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "desc2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the description name can be extracted\n",
    "\n",
    "description2=[]\n",
    "for i in desc2:\n",
    "    description2.append(i.text)\n",
    "description2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the price 81-120\n",
    "pr2=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "pr2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the price can be extracted\n",
    "\n",
    "price2=[]\n",
    "for i in pr2:\n",
    "    price2.append(i.text)\n",
    "price2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the discount 81-120\n",
    "dis2=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "dis2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the price can be extracted\n",
    "\n",
    "discount2=[]\n",
    "for i in dis2:\n",
    "    discount2.append(i.text)\n",
    "discount2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the list togetter\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "pricesun = list(chain(price,price1 ,price2))\n",
    "pricesun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionsun = list(chain(description,description1,description2))\n",
    "descriptionsun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brandsun = list(chain(brand,brand1,brand2))\n",
    "brandsun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discountsun = list(chain(discount,discount1,discount2))\n",
    "discountsun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "sunglasses=pd.DataFrame(())\n",
    "\n",
    "sunglasses['Brand']=brandsun[0:101]\n",
    "sunglasses['Product Detail']=descriptionsun[0:101]\n",
    "sunglasses['Price']=pricesun[0:101]\n",
    "sunglasses['Discount']=discountsun[0:101]\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar=[]\n",
    "for i in ra:\n",
    "    ratingstar.append(i.text)\n",
    "ratingstar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review=[]\n",
    "for i in rev:\n",
    "    review.append(i.text)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview=[]\n",
    "for i in derev:\n",
    "    dereview.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra1=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar1=[]\n",
    "for i in ra1:\n",
    "    ratingstar1.append(i.text)\n",
    "ratingstar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev1=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review1=[]\n",
    "for i in rev1:\n",
    "    review1.append(i.text)\n",
    "review1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev1=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview1=[]\n",
    "for i in derev1:\n",
    "    dereview1.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra2=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar2=[]\n",
    "for i in ra2:\n",
    "    ratingstar2.append(i.text)\n",
    "ratingstar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev2=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review2=[]\n",
    "for i in rev2:\n",
    "    review2.append(i.text)\n",
    "review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev2=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview2=[]\n",
    "for i in derev2:\n",
    "    dereview2.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra3=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra3\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar3=[]\n",
    "for i in ra3:\n",
    "    ratingstar3.append(i.text)\n",
    "ratingstar3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev3=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev3\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review3=[]\n",
    "for i in rev3:\n",
    "    review3.append(i.text)\n",
    "review3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev3=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev3\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview3=[]\n",
    "for i in derev3:\n",
    "    dereview3.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra4=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra4\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar4=[]\n",
    "for i in ra4:\n",
    "    ratingstar4.append(i.text)\n",
    "ratingstar4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev4=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev4\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review4=[]\n",
    "for i in rev4:\n",
    "    review4.append(i.text)\n",
    "review4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev4=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev4\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview4=[]\n",
    "for i in derev4:\n",
    "    dereview4.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra5=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra5\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar5=[]\n",
    "for i in ra5:\n",
    "    ratingstar5.append(i.text)\n",
    "ratingstar5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev5=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev5\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review5=[]\n",
    "for i in rev5:\n",
    "    review5.append(i.text)\n",
    "review5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev5=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev5\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview5=[]\n",
    "for i in derev5:\n",
    "    dereview5.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra6=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra6\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar6=[]\n",
    "for i in ra6:\n",
    "    ratingstar6.append(i.text)\n",
    "ratingstar6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev6=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev6\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review6=[]\n",
    "for i in rev6:\n",
    "    review6.append(i.text)\n",
    "review6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev6=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev6\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview6=[]\n",
    "for i in derev6:\n",
    "    dereview6.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra7=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra7\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar7=[]\n",
    "for i in ra7:\n",
    "    ratingstar7.append(i.text)\n",
    "ratingstar7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev7=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev7\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review7=[]\n",
    "for i in rev7:\n",
    "    review7.append(i.text)\n",
    "review7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev7=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev7\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview7=[]\n",
    "for i in derev7:\n",
    "    dereview7.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra8=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra8\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar8=[]\n",
    "for i in ra8:\n",
    "    ratingstar8.append(i.text)\n",
    "ratingstar8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev8=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev8\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review8=[]\n",
    "for i in rev8:\n",
    "    review8.append(i.text)\n",
    "review8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev8=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev8\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview8=[]\n",
    "for i in derev8:\n",
    "    dereview8.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "ra9=driver.find_elements_by_xpath(\"//*[@class='_3LWZlK _1BLPMq']\")\n",
    "ra9\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "ratingstar9=[]\n",
    "for i in ra9:\n",
    "    ratingstar9.append(i.text)\n",
    "ratingstar9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "rev9=driver.find_elements_by_xpath(\"//*[@class='_2-N8zT']\")\n",
    "rev9\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "review9=[]\n",
    "for i in rev9:\n",
    "    review9.append(i.text)\n",
    "review9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the ratingstar\n",
    "derev9=driver.find_elements_by_xpath(\"//*[@class='t-ZTKy']\")\n",
    "derev9\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "dereview9=[]\n",
    "for i in derev9:\n",
    "    dereview9.append(i.text.replace(\"\\n\",\"\"))\n",
    "dereview9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = list(chain(ratingstar,ratingstar1,ratingstar2,ratingstar3,ratingstar4,ratingstar5,ratingstar6,ratingstar7,ratingstar8,ratingstar9))\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewiphone = list(chain(review,review1,review2,review3,review4,review5,review6,review7,review8,review9))\n",
    "reviewiphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreviewiphone = list(chain(dereview,dereview1,dereview2,dereview3,dereview4,dereview5,dereview6,dereview7,dereview8,dereview9))\n",
    "dreviewiphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "iphone=pd.DataFrame(())\n",
    "\n",
    "iphone['Rating']=ratings\n",
    "iphone[' Short Review']=reviewiphone\n",
    "iphone['Detail Review']=dreviewiphone\n",
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4=\"https://www.flipkart.com/\"\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys(\"Sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn1=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "ser_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand sneakers name\n",
    "Sbr=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Sbr\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "Sbrand=[]\n",
    "for i in Sbr:\n",
    "    Sbrand.append(i.text)\n",
    "Sbrand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker description name\n",
    "Sdesc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Sdesc\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker description name can be extracted\n",
    "\n",
    "Sdescription=[]\n",
    "for i in Sdesc:\n",
    "    Sdescription.append(i.text)\n",
    "Sdescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to extract the  Sneaker price\n",
    "Spr=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Spr\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Sprice=[]\n",
    "for i in Spr:\n",
    "    Sprice.append(i.text)\n",
    "Sprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the Sneaker discount\n",
    "Sdis=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Sdis\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Sdiscount=[]\n",
    "for i in Sdis:\n",
    "    Sdiscount.append(i.text)\n",
    "Sdiscount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand sneakers name 41-80\n",
    "Sbr1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Sbr1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "Sbrand1=[]\n",
    "for i in Sbr1:\n",
    "    Sbrand1.append(i.text)\n",
    "Sbrand1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker description name 41-80\n",
    "Sdesc1=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Sdesc1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker description name can be extracted\n",
    "\n",
    "Sdescription1=[]\n",
    "for i in Sdesc1:\n",
    "    Sdescription1.append(i.text)\n",
    "Sdescription1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker price\n",
    "Spr1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Spr1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Sprice1=[]\n",
    "for i in Spr1:\n",
    "    Sprice1.append(i.text)\n",
    "Sprice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the Sneaker discount 41-80\n",
    "Sdis1=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Sdis1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Sdiscount1=[]\n",
    "for i in Sdis1:\n",
    "    Sdiscount1.append(i.text)\n",
    "Sdiscount1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand sneakers name 81-120\n",
    "Sbr2=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Sbr2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "Sbrand2=[]\n",
    "for i in Sbr2:\n",
    "    Sbrand2.append(i.text)\n",
    "Sbrand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker price 81-120\n",
    "Spr2=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Spr2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Sprice2=[]\n",
    "for i in Spr2:\n",
    "    Sprice2.append(i.text)\n",
    "Sprice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker description name 81-120\n",
    "Sdesc2=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Sdesc2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker description name can be extracted\n",
    "\n",
    "Sdescription2=[]\n",
    "for i in Sdesc2:\n",
    "    Sdescription2.append(i.text)\n",
    "Sdescription2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the Sneaker discount 81-120\n",
    "Sdis2=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Sdis2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Sdiscount2=[]\n",
    "for i in Sdis2:\n",
    "    Sdiscount2.append(i.text)\n",
    "Sdiscount2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priceSnea = list(chain(Sprice,Sprice1 ,Sprice2))\n",
    "priceSnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionSnea = list(chain(Sdescription,Sdescription1,Sdescription2))\n",
    "len(descriptionSnea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brandSnea = list(chain(Sbrand,Sbrand1,Sbrand2))\n",
    "brandSnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discountSnea = list(chain(Sdiscount,Sdiscount1,Sdiscount2))\n",
    "discountSnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "sneaker=pd.DataFrame(())\n",
    "\n",
    "sneaker['Brand']=brandSnea[0:100]\n",
    "sneaker['Product Detail']=descriptionSnea[0:100]\n",
    "sneaker['Price']=priceSnea[0:100]\n",
    "sneaker['Discount']=discountSnea[0:100]\n",
    "sneaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4=\"https://www.myntra.com/shoes\"\n",
    "\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand sneakers name\n",
    "Myntra_br=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "Myntra_br\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "Myntra_brand=[]\n",
    "for i in Myntra_br:\n",
    "    Myntra_brand.append(i.text)\n",
    "Myntra_brand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker price\n",
    "Myntra_pr=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "Myntra_pr\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Myntra_price=[]\n",
    "for i in Myntra_pr:\n",
    "    Myntra_price.append(i.text)\n",
    "Myntra_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Shoe description name \n",
    "Myntra_desc=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "Myntra_desc\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Shoe description name can be extracted\n",
    "\n",
    "Myntra_description=[]\n",
    "for i in Myntra_desc:\n",
    "    Myntra_description.append(i.text)\n",
    "Myntra_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand sneakers name\n",
    "Myntra_br1=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "Myntra_br1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "Myntra_brand1=[]\n",
    "for i in Myntra_br1:\n",
    "    Myntra_brand1.append(i.text)\n",
    "Myntra_brand1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Sneaker price\n",
    "Myntra_pr1=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "Myntra_pr1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Sneaker price can be extracted\n",
    "\n",
    "Myntra_price1=[]\n",
    "for i in Myntra_pr1:\n",
    "    Myntra_price1.append(i.text)\n",
    "Myntra_price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the  Shoe description name \n",
    "Myntra_desc1=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "Myntra_desc1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Shoe description name can be extracted\n",
    "\n",
    "Myntra_description1=[]\n",
    "for i in Myntra_desc1:\n",
    "    Myntra_description1.append(i.text)\n",
    "Myntra_description1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mbrand = list(chain(Myntra_brand,Myntra_brand1 ))\n",
    "Mbrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mprice = list(chain(Myntra_price ,Myntra_price1))\n",
    "Mprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdescription = list(chain(Myntra_description,Myntra_description1))\n",
    "Mdescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "shoe=pd.DataFrame(())\n",
    "\n",
    "shoe['Brand']=Mbrand[0:100]\n",
    "shoe['Product Detail']=Mdescription[0:100]\n",
    "shoe['Price']=Mprice[0:100]\n",
    "shoe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4=\"https://www.amazon.com/\"\n",
    "\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "ser1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1=driver.find_element_by_xpath(\"//span[@class='a-size-base a-color-base']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to extract the brand sneakers name\n",
    "titl=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "titl\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "title1=[]\n",
    "for i in titl:\n",
    "    title1.append(i.text)\n",
    "title1 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the brand sneakers name\n",
    "pri=driver.find_elements_by_xpath(\"//span[@class='a-price']\")\n",
    "pri\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the brand name can be extracted\n",
    "\n",
    "pricelap=[]\n",
    "for i in pri:\n",
    "    pricelap.append(i.text.replace('\\n',''))\n",
    "pricelap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srapping of data\n",
    "\n",
    "laptop=pd.DataFrame(())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop['Title']=title1[0:10] \n",
    "laptop['Price']=pricelap[0:10]\n",
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
