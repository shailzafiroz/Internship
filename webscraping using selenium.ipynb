{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.naukri.com/\"\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "ser_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "ser_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the job titles can be extracted\n",
    "\n",
    "job_title=[]\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name=[]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the job location can be extracted\n",
    "\n",
    "job_loc=[]\n",
    "for i in loc_tags:\n",
    "    job_loc.append(i.text)\n",
    "job_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the experience\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becoz text do not work in text so we use loop so that the job location can be extracted\n",
    "\n",
    "experience=[]\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "naukrijob=pd.DataFrame(())\n",
    "naukrijob['Job Title']=job_title[0:10]\n",
    "naukrijob['Job Location']=job_loc[0:10]\n",
    "naukrijob['Company Name']=company_name[0:10]\n",
    "naukrijob['Experience']=experience[0:10]\n",
    "\n",
    "naukrijob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.naukri.com/\"\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "serch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "ser_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags\n",
    "# becoz text do not work in text so we use loop so that the job titles can be extracted\n",
    "\n",
    "job_title=[]\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name=[]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "loc_tags\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the job location can be extracted\n",
    "\n",
    "job_loc=[]\n",
    "for i in loc_tags:\n",
    "    job_loc.append(i.text)\n",
    "job_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpurl=[]\n",
    "\n",
    "for i in url:\n",
    "    jpurl.append(i.get_attribute('href'))\n",
    "jpurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_position=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in jpurl:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting Job Position\n",
    "    try:\n",
    "        job_position=driver.find_element_by_xpath(\"//div[@class='nConfig_textblock ']//div\")\n",
    "        job_position.append(job_position.text)\n",
    "    except:\n",
    "       job_position.append('--')\n",
    "        \n",
    "job_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "naukrijob1=pd.DataFrame(())\n",
    "naukrijob1['Job Title']=job_title[0:10]\n",
    "naukrijob1['Job Location']=job_loc[0:10]\n",
    "naukrijob1['Company Name']=company_name[0:10]\n",
    "naukrijob1['Job Position']=job_position[0:10]\n",
    "\n",
    "naukrijob1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.naukri.com/\"\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "serch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_element_by_xpath(\"//label[@class='chkLbl']\")\n",
    "loc_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locfilter=driver.find_element_by_id(\"chk-Delhi / NCR-cityTypeGid-]\")\n",
    "locfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2=\"https://www.glassdoor.co.in/sitedirectory/title-jobs.htm\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job1=driver.find_element_by_id(\"scKeyword\")\n",
    "serch_job1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job1.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc1=driver.find_element_by_id(\"scLocation\")\n",
    "ser_loc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc1.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='pl-0 pr-xsm SearchStyles__searchKeywordSubmit']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags1=driver.find_elements_by_xpath(\"//a[@class=' job-search-key-l2wjgv e1n63ojh0 jobLink']\")\n",
    "company_tags1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name1=[]\n",
    "for i in company_tags1:\n",
    "    company_name1.append(i.text)\n",
    "company_name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the No of days job posted\n",
    "noofD=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "noofD\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the No of days job poste can be extracted\n",
    "\n",
    "Agejob=[]\n",
    "for i in noofD:\n",
    "    Agejob.append(i.text)\n",
    "Agejob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(\" \" in Agejob) :\n",
    "    Agejob.remove(\" \")\n",
    "Agejob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the rating\n",
    "rate=driver.find_elements_by_xpath(\"//li[@class='react-job-listing job-search-key-nhtksm eigr9kq0']//span[@class=' job-search-key-srfzj0 e1cjmv6j0']\")\n",
    "rate\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the rating can be extracted\n",
    "\n",
    "rating=[]\n",
    "for i in rate:\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "job=pd.DataFrame(())\n",
    "\n",
    "job['Company Name']=company_name1[0:10]\n",
    "job['No of days Job Posted']=Agejob[0:10]\n",
    "job['Rating']=rating[0:10]\n",
    "job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job2=driver.find_element_by_id(\"KeywordSearch\")\n",
    "serch_job2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serch_job2.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_loc2=driver.find_element_by_id(\"LocationSearch\")\n",
    "ser_loc2.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "ser_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the company name\n",
    "company_tags2=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "company_tags2\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "company_name2=[]\n",
    "for i in company_tags2:\n",
    "    company_name2.append(i.text)\n",
    "company_name2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the min_max salary\n",
    "min_max=driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "min_max\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the min_max salary can be extracted\n",
    "\n",
    "minimum_max=[]\n",
    "for i in min_max:\n",
    "    minimum_max.append(i.text)\n",
    "minimum_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the Average salary\n",
    "avg=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "avg\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the Average salary can be extracted\n",
    "\n",
    "avg_sal=[]\n",
    "for i in avg:\n",
    "    avg_sal.append(i.text.replace(\"\\n\",\"\"))\n",
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the rating\n",
    "rate1=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-center mt-xxsm']\")\n",
    "rate1\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the rating can be extracted\n",
    "\n",
    "rating1=[]\n",
    "for i in rate1:\n",
    "    rating1.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the data in dataframe \n",
    "job1=pd.DataFrame(())\n",
    "\n",
    "job1['Company Name']=company_name2[0:10]\n",
    "job1['Minimum Salary and Maxmimum Salary']=minimum_max[0:10]\n",
    "job1['Average Salary']=avg_sal[0:10]\n",
    "job1['Rating']=rating1[0:10]\n",
    "job1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4=\"https://www.flipkart.com/\"\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5f21a1c422e5daae9c52831571f745d6\", element=\"fbdbb23b-6e8c-485d-ab10-bb3a73237c16\")>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5f21a1c422e5daae9c52831571f745d6\", element=\"61315d02-58b2-4680-8d8a-c1341a6d0e94\")>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_btn1=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "ser_btn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SRPM',\n",
       " 'NuVew',\n",
       " 'kingsunglasses',\n",
       " 'kingsunglasses',\n",
       " 'Elligator',\n",
       " 'ROYAL SON',\n",
       " 'Singco',\n",
       " 'kingsunglasses',\n",
       " 'GANSTA',\n",
       " 'GANSTA',\n",
       " 'SUNBEE',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'SUNBEE',\n",
       " 'Singco India',\n",
       " 'PIRASO',\n",
       " 'DEIXELS',\n",
       " 'Elligator',\n",
       " 'povty',\n",
       " 'PHENOMENAL',\n",
       " 'Elligator',\n",
       " 'ROYAL SON',\n",
       " 'hipe',\n",
       " 'kingsunglasses',\n",
       " 'kingsunglasses',\n",
       " 'Rich Club',\n",
       " 'SUNBEE',\n",
       " 'kingsunglasses',\n",
       " 'SUNBEE',\n",
       " 'kingsunglasses',\n",
       " 'ROYAL SON',\n",
       " 'ROYAL SON',\n",
       " 'Elligator',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'PIRASO',\n",
       " 'Fastrack',\n",
       " 'NuVew',\n",
       " 'GANSTA',\n",
       " 'kingsunglasses',\n",
       " 'hipe']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to extract the company name\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "br\n",
    "\n",
    "# becoz text do not work in text so we use loop so that the company name can be extracted\n",
    "\n",
    "brand=[]\n",
    "for i in br:\n",
    "    brand.append(i.text)\n",
    "brand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5f21a1c422e5daae9c52831571f745d6\", element=\"8a593337-32b5-4256-8851-13739b2353b2\")>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next1=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "next1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
